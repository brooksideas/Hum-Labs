{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6190f6f-8add-4049-ae7e-9a0a6fe5517f",
   "metadata": {},
   "source": [
    "### Create Sqlite Database with the Works Object Column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec878ab-b6e1-4504-ab4f-b5a49c89f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "# Function to extract keys from JSONL file\n",
    "def extract_keys_from_jsonl(file_path):\n",
    "    with open(file_path) as f:\n",
    "        line = f.readline()\n",
    "        data = json.loads(line)\n",
    "        return list(data.keys())\n",
    "\n",
    "# Function to create table in SQLite\n",
    "def create_table_if_not_exists(table_name, keys):\n",
    "    conn = sqlite3.connect('sqlite3.db')\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Create table if not exists\n",
    "    c.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join([f'{key} TEXT' for key in keys])})\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Path to your JSONL file\n",
    "jsonl_file_path = 'part.jsonl'\n",
    "\n",
    "# Extract keys from JSONL file\n",
    "keys = extract_keys_from_jsonl(jsonl_file_path)\n",
    "\n",
    "# Table name\n",
    "table_name = 'part_sqlite3_table'\n",
    "\n",
    "# Create table in SQLite\n",
    "create_table_if_not_exists(table_name, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736774c9-ee23-4dca-8d97-df689d76145b",
   "metadata": {},
   "source": [
    "#### Display the Sqlite headers for confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc14e2b-ddd7-43e9-b683-ac145dc7e952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Columns: ['id', 'doi', 'doi_registration_agency', 'display_name', 'title', 'publication_year', 'publication_date', 'language', 'ids', 'primary_location', 'best_oa_location', 'type', 'open_access', 'authorships', 'corresponding_author_ids', 'corresponding_institution_ids', 'cited_by_count', 'summary_stats', 'biblio', 'is_retracted', 'is_paratext', 'concepts', 'mesh', 'locations_count', 'locations', 'referenced_works', 'referenced_works_count', 'sustainable_development_goals', 'grants', 'apc_list', 'apc_paid', 'related_works', 'abstract_inverted_index', 'counts_by_year', 'cited_by_api_url', 'updated_date', 'created_date', 'updated', 'authors_count', 'concepts_count']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Function to get table columns\n",
    "def get_table_columns(table_name):\n",
    "    conn = sqlite3.connect('sqlite3.db')\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Query to get table columns\n",
    "    c.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = [row[1] for row in c.fetchall()]\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return columns\n",
    "\n",
    "# Table name\n",
    "table_name = 'part_sqlite3_table'\n",
    "\n",
    "# Get table columns\n",
    "columns = get_table_columns(table_name)\n",
    "print(\"Table Columns:\", columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1a685-2c09-4880-8757-23df28db21b8",
   "metadata": {},
   "source": [
    "### Create Sqlitedict Database with the Works Object Column headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617b3ef7-5812-4c69-9b92-e01b5003edbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqlitedict_table']\n"
     ]
    }
   ],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "import json\n",
    "\n",
    "# Function to create SqliteDict with dynamic table and column names\n",
    "def create_sqldict_with_dynamic_schema(file_path, table_name):\n",
    "    keys = extract_keys_from_jsonl(file_path)\n",
    "\n",
    "    sqldict = SqliteDict(\"sqlitedict.sqlite\", tablename=table_name, autocommit=True)\n",
    "\n",
    "    # Insert data into SqliteDict\n",
    "    with sqldict:\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                key = data.get('id')  # Assuming 'id' is unique and used as key\n",
    "                sqldict[key] = data\n",
    "\n",
    "    return sqldict\n",
    "\n",
    "# Path to your JSONL file\n",
    "jsonl_file_path = 'part.jsonl'\n",
    "\n",
    "# Table name\n",
    "table_name = 'sqlitedict_table'\n",
    "\n",
    "# Create SqliteDict with dynamic schema\n",
    "sqldict = create_sqldict_with_dynamic_schema(jsonl_file_path, table_name)\n",
    "\n",
    "# Get table names from the SQLite database\n",
    "tables = sqldict.get_tablenames('sqlitedict.sqlite')\n",
    "print(tables)\n",
    "\n",
    "# Close the SqliteDict\n",
    "sqldict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68c9bc-8100-4c82-8a82-8a4f11f96fab",
   "metadata": {},
   "source": [
    "#### Display the Sqlitedict headers for confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c3f58-28c6-4835-a05c-4c19b83f1c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "\n",
    "# Function to get column names (headers) from SqliteDict table\n",
    "def get_sqldict_columns(sqldict):\n",
    "    # Get the first item from the SqliteDict\n",
    "    first_item = next(iter(sqldict.values()), None)\n",
    "    \n",
    "    # Extract column names if the dictionary is not empty\n",
    "    if first_item:\n",
    "        return list(first_item.keys())\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Create a SqliteDict object\n",
    "sqldict = SqliteDict(\"sqlitedict.sqlite\", tablename=\"sqlitedict_table\", autocommit=True)\n",
    "\n",
    "# Get column names\n",
    "columns = get_sqldict_columns(sqldict)\n",
    "print(\"Table Columns:\", columns)\n",
    "\n",
    "# Close the SqliteDict\n",
    "sqldict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2045a0-7439-4ca2-9578-d3a85c5fe84f",
   "metadata": {},
   "source": [
    "#### Compare the sqlite3 and sqlitedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0c58c-0641-4b93-a475-dc43f61da378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "Working on the 10x data now. Which is 100 rows.\n",
      "\n",
      "SQLite Write Time: 0.016738176345825195\n",
      "SqliteDict Write Time: 0.08756017684936523\n",
      "SQLite Read Time: 18.30529808998108\n",
      "SqliteDict Read Time: 0.0031557083129882812\n",
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "Working on the 100x data now. Which is 1000 rows.\n",
      "\n",
      "SQLite Write Time: 0.059914588928222656\n",
      "SqliteDict Write Time: 0.4994313716888428\n",
      "SQLite Read Time: 6.604947328567505\n",
      "SqliteDict Read Time: 0.0029964447021484375\n",
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "Working on the 1000x data now. Which is 10000 rows.\n",
      "\n",
      "SQLite Write Time: 0.5243668556213379\n",
      "SqliteDict Write Time: 4.890326023101807\n",
      "SQLite Read Time: 3.852259397506714\n",
      "SqliteDict Read Time: 0.0030155181884765625\n",
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "...........................................................................\n",
      "\n",
      "\n",
      "Working on the 10000x data now. Which is 100000 rows.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import sqlitedict\n",
    "\n",
    "# Function to insert data into SQLite\n",
    "def insert_into_sqlite(data):\n",
    "    conn = sqlite3.connect('sqlite3.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, data TEXT)''')\n",
    "    for row in data:\n",
    "        c.execute('''INSERT INTO test (data) VALUES (?)''', (json.dumps(row),))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Function to insert data into SqliteDict\n",
    "def insert_into_sqlitedict(data):\n",
    "    db = sqlitedict.SqliteDict('sqlitedict.sqlite', autocommit=True)\n",
    "    for row in data:\n",
    "        db[str(row['id'])] = row\n",
    "    db.close()\n",
    "\n",
    "# Function to read data from SQLite\n",
    "def read_from_sqlite():\n",
    "    conn = sqlite3.connect('sqlite3.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM test''')\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "# Function to read data from SqliteDict\n",
    "def read_from_sqlitedict():\n",
    "    db = sqlitedict.SqliteDict('sqlitedict.sqlite', autocommit=True)\n",
    "    data = [v for k, v in db.items()]\n",
    "    db.close()\n",
    "    return data\n",
    "\n",
    "# Load data from .jsonl file or SQLite database\n",
    "# Try different sizes\n",
    "for size_of_db in [10,100,1000, 10000 , 100000]:\n",
    "    with open(f'part_{size_of_db}.jsonl') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    # For demonstration purposes, let's assume 'data' is already loaded with test data\n",
    "    print(\"\\n...........................................................................\\n\")\n",
    "    print(f\"\\nWorking on the {size_of_db}x data now. Which is {size_of_db * 10} rows.\\n\")\n",
    "    # Test Write Performance\n",
    "    start_time = time.time()\n",
    "    insert_into_sqlite(data)\n",
    "    sqlite_write_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    insert_into_sqlitedict(data)\n",
    "    sqlitedict_write_time = time.time() - start_time\n",
    "\n",
    "    print(\"SQLite Write Time:\", sqlite_write_time)\n",
    "    print(\"SqliteDict Write Time:\", sqlitedict_write_time)\n",
    "\n",
    "    # Test Read Performance\n",
    "    start_time = time.time()\n",
    "    rows_sqlite = read_from_sqlite()\n",
    "    sqlite_read_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    rows_sqlitedict = read_from_sqlitedict()\n",
    "    sqlitedict_read_time = time.time() - start_time\n",
    "\n",
    "    print(\"SQLite Read Time:\", sqlite_read_time)\n",
    "    print(\"SqliteDict Read Time:\", sqlitedict_read_time)\n",
    "    print(\"\\n...........................................................................\\n\")\n",
    "\n",
    "    # Verify data consistency if needed\n",
    "    # assert rows_sqlite == rows_sqlitedict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3fe351-f572-4087-9816-e1fc7e5e4860",
   "metadata": {},
   "source": [
    "### Duplicate jsonl content function for Testing purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa983b1a-a9e3-42a9-b3e9-549d0a391f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Path to input file (part.jsonl)\n",
    "# input_file_path = 'part.jsonl'\n",
    "\n",
    "# # Path to output file (partmany.jsonl)\n",
    "# output_file_path = 'part_100000.jsonl'\n",
    "\n",
    "# # Number of times to repeat the content\n",
    "# repeat_count = 100000\n",
    "\n",
    "# # Read content from input file\n",
    "# with open(input_file_path, 'r') as input_file:\n",
    "#     content = input_file.read()\n",
    "\n",
    "# # Write content to output file multiple times\n",
    "# with open(output_file_path, 'w') as output_file:\n",
    "#     for _ in range(repeat_count):\n",
    "#         output_file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c223d-b89e-47f0-af37-3cf69381fc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
