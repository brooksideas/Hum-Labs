{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Get the Title - Key poistive pairs"
      ],
      "metadata": {
        "id": "JFW8u4v2FcKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "def fetch_and_store_data(url, output_file, target_count=10, delay=1):\n",
        "    # Initialize counters\n",
        "    total_keywords_count = 0\n",
        "    total_entries_count = 0\n",
        "    page_number = 1\n",
        "\n",
        "    # Loop until the target count is reached\n",
        "    while total_entries_count < target_count:\n",
        "        # Fetch data from the URL\n",
        "        response = requests.get(url + f\"&page={page_number}\")\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract relevant information and store in the desired format\n",
        "        results = data.get(\"results\", [])\n",
        "        formatted_data = []\n",
        "\n",
        "        for result in results:\n",
        "            title = result.get(\"title\", \"\")\n",
        "            keywords = result.get(\"keywords\", [])\n",
        "\n",
        "            if keywords:\n",
        "                # Extracting the top-scored keyword text\n",
        "                top_keyword = keywords[0].get(\"keyword\", \"\")\n",
        "\n",
        "                # Creating the structure {\"texts\": [\"title\", \"key\"]}\n",
        "                formatted_entry = {\"texts\": [title, top_keyword]}\n",
        "                formatted_data.append(formatted_entry)\n",
        "                total_keywords_count += 1\n",
        "\n",
        "\n",
        "        # Write to a .jsonl file\n",
        "        with open(output_file, \"a\") as jsonl_file:\n",
        "            for entry in formatted_data:\n",
        "                jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
        "                total_entries_count += 1\n",
        "        page_number += 1\n",
        "        # Delay for 2 seconds before the next API call due to rate limit\n",
        "        time.sleep(delay)\n",
        "\n",
        "    print(f\"Total entries with keywords: {total_keywords_count}\")\n",
        "    print(f\"Total entries written to {output_file}: {total_entries_count}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the URL and output file\n",
        "    api_url = \"https://api.openalex.org/works?mailto=brookshum24@gmail.com&sample=2&per-page=2&select=title,keywords\"\n",
        "    output_jsonl_file = \"title_key.jsonl\"\n",
        "\n",
        "    # Fetch and store the data\n",
        "    fetch_and_store_data(api_url, output_jsonl_file)"
      ],
      "metadata": {
        "id": "46jQSh6zPoto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Get the Title - Abstract positive pairs"
      ],
      "metadata": {
        "id": "iLCuVJMuSxjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "def fetch_and_store_data(url, output_file, target_count=3, delay=0):\n",
        "    # Initialize counters\n",
        "    total_entries_count = 0\n",
        "\n",
        "    # Loop until the target count is reached\n",
        "    while total_entries_count < target_count:\n",
        "        # Fetch data from the URL\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        print(\"data ->\", data)\n",
        "\n",
        "        # Extract relevant information and store in the desired format\n",
        "        results = data.get(\"results\", [])\n",
        "        formatted_data = []\n",
        "\n",
        "        for result in results:\n",
        "            title = result.get(\"title\", \"\")\n",
        "            abstract_index = result.get(\"abstract_inverted_index\")\n",
        "\n",
        "            # Skip processing if abstract_inverted_index is None\n",
        "            if abstract_index is None:\n",
        "                continue\n",
        "\n",
        "            # Concatenate all keys from the abstract_inverted_index using spaces\n",
        "            abstract_text = \" \".join(key for key in abstract_index.keys())\n",
        "\n",
        "            # Creating the structure {\"texts\": [\"title\", \"abstract\"]}\n",
        "            formatted_entry = {\"texts\": [title, abstract_text]}\n",
        "            formatted_data.append(formatted_entry)\n",
        "\n",
        "        # Write to a .jsonl file\n",
        "        with open(output_file, \"a\") as jsonl_file:\n",
        "            for entry in formatted_data:\n",
        "                jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
        "                total_entries_count += 1\n",
        "\n",
        "        # Delay for specified seconds before the next API call\n",
        "        time.sleep(delay)\n",
        "\n",
        "    print(f\"Total entries written to {output_file}: {total_entries_count}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the URL and output file\n",
        "    api_url = \"https://api.openalex.org/works?seed=3&sample=3&select=title,abstract_inverted_index\"\n",
        "    output_jsonl_file = \"title_abstract.jsonl\"\n",
        "\n",
        "    # Fetch and store the data\n",
        "    fetch_and_store_data(api_url, output_jsonl_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE_zyKmjS4yH",
        "outputId": "1d90cde9-a74c-430f-fe2b-d56f9651e7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data -> {'meta': {'count': 3, 'db_response_time_ms': 1025, 'page': 1, 'per_page': 25, 'groups_count': None}, 'results': [{'title': 'Minimum Dissipated Power for Linear and Nonlinear Electric Circuits', 'abstract_inverted_index': None}, {'title': 'SunTrust Banks, Inc.', 'abstract_inverted_index': {'Abstract': [0], 'Commercial': [1], 'Banking': [2], '(MIC:': [3], '8.1': [4], 'SIC:': [5], '6021': [6], 'NAIC:': [7], '522110)': [8], 'SunTrust': [9, 19], 'Banks': [10], 'is': [11], 'a': [12], 'financial': [13], 'services': [14, 44], 'holding': [15], 'company.': [16], 'Through': [17, 31], 'its': [18, 32, 68], 'Bank': [20], 'subsidiary,': [21], 'Co.': [22, 35, 48, 66, 90], 'provides': [23, 36], 'deposit,': [24], 'credit,': [25], 'and': [26, 28, 45, 61, 76, 80, 82, 97], 'trust': [27], 'investment': [29], 'services.': [30], 'other': [33], 'subsidiaries,': [34], 'banking,': [37], 'asset': [38], 'management,': [39], \"securities'\": [40], 'brokerage,': [41], 'capital': [42], 'market': [43], 'credit‐related': [46], 'insurance.': [47], 'operates': [49], 'mainly': [50], 'within': [51], 'Florida,': [52], 'Georgia,': [53], 'Maryland,': [54], 'North': [55], 'Carolina,': [56, 58], 'South': [57], 'Tennessee,': [59], 'Virginia,': [60], 'the': [62], 'District': [63], 'of': [64, 86, 94, 100], 'Columbia.': [65], 'conducted': [67], 'businesses': [69], 'through': [70], 'five': [71], 'segments:': [72], 'Retail,': [73], 'Commercial,': [74], 'Corporate': [75], 'Investment': [77, 83], 'Banking,': [78], 'Mortgage,': [79], 'Wealth': [81], 'Management.': [84], 'As': [85], 'Dec': [87], '31': [88], '2007,': [89], 'had': [91], 'total': [92, 98], 'assets': [93], '$179.6': [95], 'billion': [96], 'deposits': [99], '$117.8': [101], 'billion.': [102]}}, {'title': 'A constant rounds group key agreement protocol without using hash functions', 'abstract_inverted_index': {'Abstract': [0], 'It': [1], 'is': [2, 32], 'important': [3], 'to': [4, 12, 34], 'encrypt': [5], 'and': [6, 23, 69], 'authenticate': [7], 'messages': [8], 'sent': [9], 'over': [10], 'networks': [11], 'achieve': [13], 'security.': [14], 'Network': [15], 'users': [16], 'must': [17], 'therefore': [18], 'agree': [19], 'upon': [20], 'encryption': [21], 'keys': [22], 'authentication': [24, 36], 'keys.': [25], 'The': [26, 62], 'authenticated': [27], 'Diffie–Hellman': [28], 'key': [29, 47], 'agreement': [30, 48], 'protocol': [31, 49, 63], 'used': [33], 'provide': [35], 'in': [37, 66, 76], 'communication': [38, 68], 'systems.': [39], 'In': [40], 'this': [41], 'paper': [42], 'we': [43], 'present': [44], 'a': [45], 'group': [46], 'without': [50], 'using': [51], 'one‐way': [52], 'hash': [53], 'functions': [54], 'that': [55], 'are': [56], 'based': [57], 'on': [58], 'the': [59, 74, 77], 'DDH': [60], 'problem.': [61], 'achieves': [64], 'efficiency': [65], 'both': [67], 'computation': [70], 'aspects.': [71], 'We': [72], 'analyzed': [73], 'security': [75, 78], 'model': [79], 'formalized': [80], 'by': [81], 'Bresson': [82], 'et': [83], 'al': [84], '.': [85], 'Copyright': [86], '©': [87], '2009': [88], 'John': [89], 'Wiley': [90], '&amp;': [91], 'Sons,': [92], 'Ltd.': [93]}}], 'group_by': []}\n",
            "data -> {'meta': {'count': 3, 'db_response_time_ms': 906, 'page': 1, 'per_page': 25, 'groups_count': None}, 'results': [{'title': 'Minimum Dissipated Power for Linear and Nonlinear Electric Circuits', 'abstract_inverted_index': None}, {'title': 'SunTrust Banks, Inc.', 'abstract_inverted_index': {'Abstract': [0], 'Commercial': [1], 'Banking': [2], '(MIC:': [3], '8.1': [4], 'SIC:': [5], '6021': [6], 'NAIC:': [7], '522110)': [8], 'SunTrust': [9, 19], 'Banks': [10], 'is': [11], 'a': [12], 'financial': [13], 'services': [14, 44], 'holding': [15], 'company.': [16], 'Through': [17, 31], 'its': [18, 32, 68], 'Bank': [20], 'subsidiary,': [21], 'Co.': [22, 35, 48, 66, 90], 'provides': [23, 36], 'deposit,': [24], 'credit,': [25], 'and': [26, 28, 45, 61, 76, 80, 82, 97], 'trust': [27], 'investment': [29], 'services.': [30], 'other': [33], 'subsidiaries,': [34], 'banking,': [37], 'asset': [38], 'management,': [39], \"securities'\": [40], 'brokerage,': [41], 'capital': [42], 'market': [43], 'credit‐related': [46], 'insurance.': [47], 'operates': [49], 'mainly': [50], 'within': [51], 'Florida,': [52], 'Georgia,': [53], 'Maryland,': [54], 'North': [55], 'Carolina,': [56, 58], 'South': [57], 'Tennessee,': [59], 'Virginia,': [60], 'the': [62], 'District': [63], 'of': [64, 86, 94, 100], 'Columbia.': [65], 'conducted': [67], 'businesses': [69], 'through': [70], 'five': [71], 'segments:': [72], 'Retail,': [73], 'Commercial,': [74], 'Corporate': [75], 'Investment': [77, 83], 'Banking,': [78], 'Mortgage,': [79], 'Wealth': [81], 'Management.': [84], 'As': [85], 'Dec': [87], '31': [88], '2007,': [89], 'had': [91], 'total': [92, 98], 'assets': [93], '$179.6': [95], 'billion': [96], 'deposits': [99], '$117.8': [101], 'billion.': [102]}}, {'title': 'A constant rounds group key agreement protocol without using hash functions', 'abstract_inverted_index': {'Abstract': [0], 'It': [1], 'is': [2, 32], 'important': [3], 'to': [4, 12, 34], 'encrypt': [5], 'and': [6, 23, 69], 'authenticate': [7], 'messages': [8], 'sent': [9], 'over': [10], 'networks': [11], 'achieve': [13], 'security.': [14], 'Network': [15], 'users': [16], 'must': [17], 'therefore': [18], 'agree': [19], 'upon': [20], 'encryption': [21], 'keys': [22], 'authentication': [24, 36], 'keys.': [25], 'The': [26, 62], 'authenticated': [27], 'Diffie–Hellman': [28], 'key': [29, 47], 'agreement': [30, 48], 'protocol': [31, 49, 63], 'used': [33], 'provide': [35], 'in': [37, 66, 76], 'communication': [38, 68], 'systems.': [39], 'In': [40], 'this': [41], 'paper': [42], 'we': [43], 'present': [44], 'a': [45], 'group': [46], 'without': [50], 'using': [51], 'one‐way': [52], 'hash': [53], 'functions': [54], 'that': [55], 'are': [56], 'based': [57], 'on': [58], 'the': [59, 74, 77], 'DDH': [60], 'problem.': [61], 'achieves': [64], 'efficiency': [65], 'both': [67], 'computation': [70], 'aspects.': [71], 'We': [72], 'analyzed': [73], 'security': [75, 78], 'model': [79], 'formalized': [80], 'by': [81], 'Bresson': [82], 'et': [83], 'al': [84], '.': [85], 'Copyright': [86], '©': [87], '2009': [88], 'John': [89], 'Wiley': [90], '&amp;': [91], 'Sons,': [92], 'Ltd.': [93]}}], 'group_by': []}\n",
            "Total entries written to title_abstract.jsonl: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Get the Expanded Referenced , Related and Ngrams from Work,Object and save as a dataframe [Max 3 values]"
      ],
      "metadata": {
        "id": "jtBE0TBJDdTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Function to fetch and process referenced works\n",
        "def fetch_referenced_works(work_id):\n",
        "    # Initialize lists to store referenced and related work titles, and ngrams\n",
        "    referenced_work_titles = []\n",
        "    related_work_titles = []\n",
        "    ngrams = []\n",
        "\n",
        "    # Fetch the work details\n",
        "    work_url = f\"https://api.openalex.org/works/{work_id}\"\n",
        "    response = requests.get(work_url)\n",
        "    work_details = response.json()\n",
        "\n",
        "    work_title = work_details.get(\"title\")\n",
        "\n",
        "    # Extract and process referenced works\n",
        "    referenced_works = work_details.get(\"referenced_works\", [])\n",
        "    for referenced_work_url in referenced_works:\n",
        "        # Extract the last section of the work ID from the URL\n",
        "        last_section = referenced_work_url.rsplit(\"/\", 1)[-1]\n",
        "\n",
        "        # Construct the referenced_work_api_url\n",
        "        referenced_work_api_url = f\"https://api.openalex.org/works/{last_section}\"\n",
        "\n",
        "        # Fetch details of the referenced work\n",
        "        referenced_work_response = requests.get(referenced_work_api_url)\n",
        "        referenced_work_details = referenced_work_response.json()\n",
        "\n",
        "        # Extract title as a string and add to the list\n",
        "        referenced_work_title = str(referenced_work_details.get(\"title\", \"\"))\n",
        "        referenced_work_titles.append(referenced_work_title)\n",
        "\n",
        "    # Extract and process related works\n",
        "    related_works = work_details.get(\"related_works\", [])\n",
        "    for related_work_url in related_works:\n",
        "        # Extract the last section of the work ID from the URL\n",
        "        last_section = related_work_url.rsplit(\"/\", 1)[-1]\n",
        "\n",
        "        # Construct the related_work_api_url\n",
        "        related_work_api_url = f\"https://api.openalex.org/works/{last_section}\"\n",
        "\n",
        "        # Fetch details of the related work\n",
        "        related_work_response = requests.get(related_work_api_url)\n",
        "        related_work_details = related_work_response.json()\n",
        "\n",
        "        # Extract title as a string and add to the list\n",
        "        related_work_title = str(related_work_details.get(\"title\", \"\"))\n",
        "        related_work_titles.append(related_work_title)\n",
        "\n",
        "    # Fetch ngrams\n",
        "    ngrams_url = f\"https://api.openalex.org/works/{work_id}/ngrams\"\n",
        "    ngrams_response = requests.get(ngrams_url)\n",
        "    ngrams_data = ngrams_response.json().get(\"ngrams\", [])\n",
        "\n",
        "    # Sort ngrams in descending order based on term_frequency\n",
        "    sorted_ngrams = sorted(ngrams_data, key=lambda x: x.get(\"term_frequency\", 0), reverse=True)\n",
        "\n",
        "    # Iterate over the sorted ngrams list and select only the top 3 ngrams\n",
        "    for ngram in sorted_ngrams[:3]:\n",
        "        ngrams.append(ngram.get(\"ngram\", \"\"))\n",
        "\n",
        "    return work_title, referenced_work_titles, related_work_titles, ngrams\n",
        "\n",
        "# Create an empty DataFrame\n",
        "# columns for future use added here\n",
        "columns = [\"work_id\", \"title\", \"referenced_works\", \"related_work_titles\", \"ngrams\", \"nearest_related_work\", \"nearest_referenced_work\", \"nearest_ngrams_work\"]\n",
        "wrangled_work_df = pd.DataFrame(columns=columns)\n",
        "wrangled_work_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Sample Work ID\n",
        "work_id = \"W2961049121\"\n",
        "\n",
        "# Fetch and process referenced, related works, and ngrams\n",
        "work_title, referenced_work_titles, related_work_titles, ngrams = fetch_referenced_works(work_id)\n",
        "\n",
        "# Add a row to the DataFrame\n",
        "wrangled_work_df = pd.concat([wrangled_work_df, pd.DataFrame({\n",
        "    \"work_id\": [work_id],\n",
        "    \"title\": [work_title],\n",
        "    \"referenced_works\": [referenced_work_titles],\n",
        "    \"related_work_titles\": [related_work_titles],\n",
        "    \"ngrams\": [ngrams]\n",
        "})], ignore_index=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(len(wrangled_work_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU5DmyMhICB1",
        "outputId": "0e6702df-d359-430d-9664-8bfa0345511d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrangled_work_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "OE-StWPqIo4-",
        "outputId": "f9edd282-b9a8-4bbf-e084-7958cfdf8d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       work_id                                              title  \\\n",
              "0  W2961049121  Shape memory nanocomposite fibers for untether...   \n",
              "\n",
              "                                    referenced_works  \\\n",
              "0  [Hierarchically buckled sheath-core fibers for...   \n",
              "\n",
              "                                 related_work_titles  \\\n",
              "0  [Shape Memory and Superelastic Alloys : Techno...   \n",
              "\n",
              "                       ngrams nearest_related_work nearest_referenced_work  \\\n",
              "0  [fiber, high, temperature]                  NaN                     NaN   \n",
              "\n",
              "  nearest_ngrams_work  \n",
              "0                 NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0d32830-b724-40ab-8c0d-dc3d1de14f9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>work_id</th>\n",
              "      <th>title</th>\n",
              "      <th>referenced_works</th>\n",
              "      <th>related_work_titles</th>\n",
              "      <th>ngrams</th>\n",
              "      <th>nearest_related_work</th>\n",
              "      <th>nearest_referenced_work</th>\n",
              "      <th>nearest_ngrams_work</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W2961049121</td>\n",
              "      <td>Shape memory nanocomposite fibers for untether...</td>\n",
              "      <td>[Hierarchically buckled sheath-core fibers for...</td>\n",
              "      <td>[Shape Memory and Superelastic Alloys : Techno...</td>\n",
              "      <td>[fiber, high, temperature]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0d32830-b724-40ab-8c0d-dc3d1de14f9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0d32830-b724-40ab-8c0d-dc3d1de14f9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0d32830-b724-40ab-8c0d-dc3d1de14f9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_bdbcf1cc-04e0-4d5d-a232-f9d048f95b50\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('wrangled_work_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bdbcf1cc-04e0-4d5d-a232-f9d048f95b50 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('wrangled_work_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wrangled_work_df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrangled_work_df[\"ngrams\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yJteHGnW7Sk",
        "outputId": "8915b67b-2d53-473b-d90b-b86264b14cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fiber', 'high', 'temperature']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Ngrams with their full representations look like these values.\n",
        "\n",
        "[{'ngram': 'fiber',\n",
        "  'ngram_count': 80,\n",
        "  'ngram_tokens': 1,\n",
        "  'term_frequency': 0.025502072043353523},\n",
        " {'ngram': 'high',\n",
        "  'ngram_count': 32,\n",
        "  'ngram_tokens': 1,\n",
        "  'term_frequency': 0.010200828817341408},\n",
        " {'ngram': 'temperature',\n",
        "  'ngram_count': 31,\n",
        "  'ngram_tokens': 1,\n",
        "  'term_frequency': 0.00988205291679949}\n",
        "]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UGJBjsMn0Sg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install db-sqlite3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m60UddsA0Upp",
        "outputId": "654a4eaf-9602-47aa-824b-8aaf288c3338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting db-sqlite3\n",
            "  Downloading db-sqlite3-0.0.1.tar.gz (1.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting db (from db-sqlite3)\n",
            "  Downloading db-0.1.1.tar.gz (3.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting antiorm (from db->db-sqlite3)\n",
            "  Downloading antiorm-1.2.1.tar.gz (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: db-sqlite3, db, antiorm\n",
            "  Building wheel for db-sqlite3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for db-sqlite3: filename=db_sqlite3-0.0.1-py3-none-any.whl size=1770 sha256=da8fdd8c2bea1084076bf72ee09ac2405153c099c63fce37d69401526e1d81b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/b7/83/e941e0a0e04f417982e718ae7295d1e82b5f2863a1c51edd71\n",
            "  Building wheel for db (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for db: filename=db-0.1.1-py3-none-any.whl size=3874 sha256=af8541da3440d4d550491b8a587efbc94b0b79af207db0206d1b1857bb133aaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/e4/df/bc55b93af204ab098d9effec76f6889ad12d7ad74e833c4910\n",
            "  Building wheel for antiorm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antiorm: filename=antiorm-1.2.1-py3-none-any.whl size=31665 sha256=04df4fa137c9486446df67e33745fa1e3263453159a083ca84fc08e479d07e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/9f/7e/b7c95b391cfa77a9e722d359e9c669cf6c8d798d748aec5091\n",
            "Successfully built db-sqlite3 db antiorm\n",
            "Installing collected packages: antiorm, db, db-sqlite3\n",
            "Successfully installed antiorm-1.2.1 db-0.1.1 db-sqlite3-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrangled_work_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "tiS0GQjn2zZ1",
        "outputId": "195c04a1-dff5-4c0c-87d4-b7d4de44f782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'wrangled_work_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-27b7faec3d61>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrangled_work_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wrangled_work_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fetch accordingly using Json load"
      ],
      "metadata": {
        "id": "ZsfqpfmA4OTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query\n",
        "query = \"SELECT * FROM works_table\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "# print(results)\n",
        "# Iterate over the results\n",
        "for result in results:\n",
        "    (work_id, title,\n",
        "     referenced_works_json,\n",
        "     related_work_titles_json,\n",
        "     ngrams_json,\n",
        "     nearest_related_work_json,\n",
        "     nearest_referenced_work_json,\n",
        "     nearest_ngrams_work_json)= result\n",
        "\n",
        "    # Parse JSON strings back to Python objects\n",
        "    referenced_works = json.loads(referenced_works_json)\n",
        "    related_work_titles = json.loads(related_work_titles_json)\n",
        "    ngrams = json.loads(ngrams_json)\n",
        "\n",
        "    # Now you have the data as lists of strings\n",
        "    print(\"Work ID:\", work_id)\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Referenced Works:\", referenced_works, type(referenced_works))\n",
        "    print(\"Related Work Titles:\", related_work_titles, type(related_work_titles[0]))\n",
        "    print(\"Ngrams:\", ngrams)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7BIbueO3yhF",
        "outputId": "dcc16853-4e63-41dd-d1e9-4c0e6e43b3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Work ID: W2961049121\n",
            "Title: Shape memory nanocomposite fibers for untethered high-energy microengines\n",
            "Referenced Works: ['Hierarchically buckled sheath-core fibers for superelastic electronics, sensors, and muscles', '8—THE MEASUREMENT OF TORSIONAL RELAXATION IN TEXTILE FIBRES', 'Quantifying the Shape-Memory Effect of Polymers by Cyclic Thermomechanical Tests', 'Fibers Do the Twist', 'A micro rotary actuator using shape memory alloys', 'Scalable process for the spinning of PVA–carbon nanotube composite fibers', 'Shape and Temperature Memory of Nanocomposites with Broadened Glass Transition', 'Bacterial flagellar motor', 'Performance test and improvement of piezoelectric torsional actuators', 'Temperature‐Memory Polymer Networks with Crystallizable Controlling Units', 'Hybrid carbon nanotube yarn artificial muscle inspired by spider dragline silk', 'Differential scanning calorimetry of crystallized PVA hydrogels', 'How polymers lose memory with age', 'Alginate/graphene oxide fibers with enhanced mechanical strength prepared by wet spinning', 'Polylactide-based polyurethane and its shape-memory behavior', 'Biodegradable, Elastic Shape-Memory Polymers for Potential Biomedical Applications', 'Multifunctional Shape‐Memory Polymers', 'Improved structure and properties of single-wall carbon nanotube spun fibers', 'Artificial Muscles from Fishing Line and Sewing Thread', 'Niobium Nanowire Yarns and their Application as Artificial Muscles', 'Hot-Drawing of Single and Multiwall Carbon Nanotube Fibers for High Toughness and Alignment', 'Polymer artificial muscles', 'Electrically, Chemically, and Photonically Powered Torsional and Tensile Actuation of Hybrid Carbon Nanotube Yarn Muscles', 'Torsional Carbon Nanotube Artificial Muscles', 'A Novel Electromechanical Actuation Mechanism of a Carbon Nanotube Fiber', 'Super-tough carbon-nanotube fibres', 'Temperature-memory polymer actuators', 'Efficient, Absorption‐Powered Artificial Muscles Based on Carbon Nanotube Hybrid Yarns', 'Effect of the Deformation Temperature on the Shape‐Memory Behavior of Epoxy Networks', 'Bacterial flagellar motor', 'Tunable polymer multi-shape memory effect', 'A Mechanically Actuating Carbon‐Nanotube Fiber in Response to Water and Moisture', 'Fiber-Directed Conjugated-Polymer Torsional Actuator: Nonlinear Elasticity Modeling and Experimental Validation', 'Moisture‐Activated Torsional Graphene‐Fiber Motor', 'Thermally induced shape‐memory effects in polymers: Quantification and related modeling approaches', 'Body temperature triggered shape‐memory polymers with high elastic energy storage capacity', 'Hierarchically arranged helical fibre actuators driven by solvents and vapours', 'Bio-inspired, Moisture-Powered Hybrid Carbon Nanotube Yarn Muscles', 'Thermal Conductivity, Heat Capacity, and Elastic Constants of Water-Soluble Polymers and Polymer Blends', 'Biomechanics', 'New twist on artificial muscles', 'Fast Torsional Artificial Muscles from NiTi Twisted Yarns', 'The grand challenges of <i>Science Robotics</i>', 'Reprogrammable recovery and actuation behaviour of shape-memory polymers', 'Synthetic Fibers'] <class 'list'>\n",
            "Related Work Titles: ['Shape Memory and Superelastic Alloys : Technologies and Applications', 'Martensitic transformation and shape memory effect of Ni49.6Ti45.4Ta5 shape memory alloy', 'Structure and property of Cu-based thermosensitive nanocomposite', 'Bulk Metal and Ceramics Nanocomposites', 'Shape Memory Alloys', 'Innovations and recent trends in Shape Memory Alloy: a review', 'Compressive deformation and shape recovery behavior of Zr-Cu-Al shape memory alloy', 'Shape Memory Alloys: Manufacture, Properties and Applications', 'A novel review on shape memory alloy and their applications in extraterrestrial roving missions', \"Shape memory materials : proceedings of the International Symposium and Exhibition on Shape Memory Materials (SMM '99), held in Kanazawa, Japan, in May 1999\"] <class 'str'>\n",
            "Ngrams: ['fiber', 'high', 'temperature']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Now** expand the above code to iterate over the batch of sampled data"
      ],
      "metadata": {
        "id": "jmEeIsMG4ugv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Function to fetch and process referenced works\n",
        "def fetch_referenced_works(work_id):\n",
        "    # Initialize an empty list to store referenced work titles\n",
        "    referenced_work_titles = []\n",
        "    related_work_titles = []\n",
        "    ngrams_list = []\n",
        "\n",
        "    # Fetch the work details\n",
        "    work_url = f\"https://api.openalex.org/works/{work_id}\"\n",
        "    response = requests.get(work_url)\n",
        "    work_details = response.json()\n",
        "\n",
        "    work_title = work_details.get(\"title\")\n",
        "\n",
        "    # Extract and process referenced works\n",
        "    referenced_works = work_details.get(\"referenced_works\", [])[:3]  # Limit to the first 3 references\n",
        "    for referenced_work_url in referenced_works:\n",
        "        # Extract the last section of the work ID from the URL\n",
        "        last_section = referenced_work_url.rsplit(\"/\", 1)[-1]\n",
        "\n",
        "        # Construct the referenced_work_api_url\n",
        "        referenced_work_api_url = f\"https://api.openalex.org/works/{last_section}\"\n",
        "\n",
        "        # Fetch details of the referenced work\n",
        "        referenced_work_response = requests.get(referenced_work_api_url)\n",
        "        referenced_work_details = referenced_work_response.json()\n",
        "\n",
        "        # Extract title as a string and add to the list\n",
        "        referenced_work_title = str(referenced_work_details.get(\"title\", \"\"))\n",
        "        referenced_work_titles.append(referenced_work_title)\n",
        "\n",
        "    # Extract and process related works\n",
        "    related_works = work_details.get(\"related_works\", [])[:3]  # Limit to the first 3 related works\n",
        "    for related_work_url in related_works:\n",
        "        # Extract the last section of the work ID from the URL\n",
        "        last_section = related_work_url.rsplit(\"/\", 1)[-1]\n",
        "\n",
        "        # Construct the related_work_api_url\n",
        "        related_work_api_url = f\"https://api.openalex.org/works/{last_section}\"\n",
        "\n",
        "        # Fetch details of the related work\n",
        "        related_work_response = requests.get(related_work_api_url)\n",
        "        related_work_details = related_work_response.json()\n",
        "\n",
        "        # Extract title as a string and add to the list\n",
        "        related_work_title = str(related_work_details.get(\"title\", \"\"))\n",
        "        related_work_titles.append(related_work_title)\n",
        "\n",
        "    # Fetch ngrams data\n",
        "    ngrams_url = f\"https://api.openalex.org/works/{work_id}/ngrams\"\n",
        "    ngrams_response = requests.get(ngrams_url)\n",
        "    ngrams_data = ngrams_response.json().get(\"ngrams\", [])\n",
        "\n",
        "    # Sort ngrams_data by term_frequency in descending order\n",
        "    ngrams_data.sort(key=lambda x: x.get(\"term_frequency\", 0), reverse=True)\n",
        "\n",
        "    # Select only the top 3 ngrams\n",
        "    selected_ngrams = [ngram.get(\"ngram\", \"\") for ngram in ngrams_data[:3]]\n",
        "    ngrams_list.extend(selected_ngrams)\n",
        "\n",
        "    return work_title, referenced_work_titles, related_work_titles, ngrams_list\n",
        "\n",
        "# Create an empty DataFrame\n",
        "# Create an empty DataFrame with the required columns\n",
        "columns = [\"work_id\", \"title\", \"referenced_works\", \"related_work_titles\", \"ngrams\", \"nearest_related_work\", \"nearest_referenced_work\", \"nearest_ngrams_work\"]\n",
        "wrangled_work_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Fetch the sampled size Work IDs\n",
        "\n",
        "# Fetch the sample work IDs\n",
        "works_url = \"https://api.openalex.org/works?sample=10&seed=3&select=id\"\n",
        "works_response = requests.get(works_url)\n",
        "works_data = works_response.json()\n",
        "\n",
        "# Extract IDs from the results list\n",
        "work_ids = [work.get(\"id\", \"\").rsplit(\"/\", 1)[-1] for work in works_data.get(\"results\", [])]\n",
        "\n",
        "# work_ids has the form ['W4205227400', 'W2015602200'...]\n",
        "\n",
        "# Fetch and process referenced, related works, and ngrams for each work ID\n",
        "for work_id in work_ids:\n",
        "    work_title, referenced_work_titles, related_work_titles, ngrams_list = fetch_referenced_works(work_id)\n",
        "\n",
        "    # Add a row to the DataFrame\n",
        "    wrangled_work_df = pd.concat([wrangled_work_df, pd.DataFrame({\n",
        "        \"work_id\": [work_id],\n",
        "        \"title\": [work_title],\n",
        "        \"referenced_works\": [referenced_work_titles],\n",
        "        \"related_work_titles\": [related_work_titles],\n",
        "        \"ngrams\": [ngrams_list]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(wrangled_work_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iznweH-G42md",
        "outputId": "0e2ff95e-9afb-461e-8d1f-e8220b2f56cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       work_id                                              title  \\\n",
            "0  W4205227400                               SunTrust Banks, Inc.   \n",
            "1  W2015602200  A constant rounds group key agreement protocol...   \n",
            "2  W2952852381  Equity investigation of attitudinal shifts in ...   \n",
            "3  W2904069587                                Chiffres et lettres   \n",
            "4  W2345552705  [Chemical control of rust (Uromyces phaseoli v...   \n",
            "5  W3000345438        Modeling text embedded information cascades   \n",
            "6  W2008986850  Estimation of mortality coefficients and survi...   \n",
            "7  W4253524524  Universal Screening of SARS-CoV-2 of Oncology ...   \n",
            "8  W4310782751  THE RELATIONSHIP OF CLINICAL AND MORPHOLOGICAL...   \n",
            "9  W1592839950  The health of the school child? An historical ...   \n",
            "\n",
            "                                    referenced_works  \\\n",
            "0                                                 []   \n",
            "1  [Scalable Protocols for Authenticated Group Ke...   \n",
            "2  [Modeling theory applied: Modeling Instruction...   \n",
            "3                                                 []   \n",
            "4                                                 []   \n",
            "5  [Feature-Enhanced Probabilistic Models for Dif...   \n",
            "6  [Predicted decline of protected whales based o...   \n",
            "7                                                 []   \n",
            "8  [Titanium Mesh Shaping and Fixation for the Tr...   \n",
            "9                                                 []   \n",
            "\n",
            "                                 related_work_titles                ngrams  \\\n",
            "0  [Regulation, Deregulation, Reregulation: The F...                    []   \n",
            "1  [Authentication for distributed systems, Resea...           [1, key, ]   \n",
            "2  [Anticipating the inevitable: When leader and ...                    []   \n",
            "3                                                 []                    []   \n",
            "4                                                 []                    []   \n",
            "5  [Development of a practical system for text co...                    []   \n",
            "6  [Dwarf Minke Whale (Balaenoptera acutorostrata...  [t, estimate, whale]   \n",
            "7  [Nipah virus outbreak with person-to-person tr...                    []   \n",
            "8  [[The healing of osteotomies of the lower jaw ...                    []   \n",
            "9  [The Causes Analysis and Measures of Electrica...                    []   \n",
            "\n",
            "  nearest_related_work nearest_referenced_work nearest_ngrams_work  \n",
            "0                  NaN                     NaN                 NaN  \n",
            "1                  NaN                     NaN                 NaN  \n",
            "2                  NaN                     NaN                 NaN  \n",
            "3                  NaN                     NaN                 NaN  \n",
            "4                  NaN                     NaN                 NaN  \n",
            "5                  NaN                     NaN                 NaN  \n",
            "6                  NaN                     NaN                 NaN  \n",
            "7                  NaN                     NaN                 NaN  \n",
            "8                  NaN                     NaN                 NaN  \n",
            "9                  NaN                     NaN                 NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checks it is in proper form"
      ],
      "metadata": {
        "id": "mDTDQpi7y-f-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wrangled_work_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "9aBYC4rAzCIo",
        "outputId": "c484e82a-995d-485c-8531-92f3431ffe6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       work_id                                              title  \\\n",
              "0  W4205227400                               SunTrust Banks, Inc.   \n",
              "1  W2015602200  A constant rounds group key agreement protocol...   \n",
              "2  W2952852381  Equity investigation of attitudinal shifts in ...   \n",
              "3  W2904069587                                Chiffres et lettres   \n",
              "4  W2345552705  [Chemical control of rust (Uromyces phaseoli v...   \n",
              "\n",
              "                                    referenced_works  \\\n",
              "0                                                 []   \n",
              "1  [Scalable Protocols for Authenticated Group Ke...   \n",
              "2  [Modeling theory applied: Modeling Instruction...   \n",
              "3                                                 []   \n",
              "4                                                 []   \n",
              "\n",
              "                                 related_work_titles       ngrams  \\\n",
              "0  [Regulation, Deregulation, Reregulation: The F...           []   \n",
              "1  [Authentication for distributed systems, Resea...  [1, key, ]   \n",
              "2  [Anticipating the inevitable: When leader and ...           []   \n",
              "3                                                 []           []   \n",
              "4                                                 []           []   \n",
              "\n",
              "  nearest_related_work nearest_referenced_work nearest_ngrams_work  \n",
              "0                  NaN                     NaN                 NaN  \n",
              "1                  NaN                     NaN                 NaN  \n",
              "2                  NaN                     NaN                 NaN  \n",
              "3                  NaN                     NaN                 NaN  \n",
              "4                  NaN                     NaN                 NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02bf2942-7d7c-4f41-82c4-1700304a5e9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>work_id</th>\n",
              "      <th>title</th>\n",
              "      <th>referenced_works</th>\n",
              "      <th>related_work_titles</th>\n",
              "      <th>ngrams</th>\n",
              "      <th>nearest_related_work</th>\n",
              "      <th>nearest_referenced_work</th>\n",
              "      <th>nearest_ngrams_work</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W4205227400</td>\n",
              "      <td>SunTrust Banks, Inc.</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Regulation, Deregulation, Reregulation: The F...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W2015602200</td>\n",
              "      <td>A constant rounds group key agreement protocol...</td>\n",
              "      <td>[Scalable Protocols for Authenticated Group Ke...</td>\n",
              "      <td>[Authentication for distributed systems, Resea...</td>\n",
              "      <td>[1, key, ]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W2952852381</td>\n",
              "      <td>Equity investigation of attitudinal shifts in ...</td>\n",
              "      <td>[Modeling theory applied: Modeling Instruction...</td>\n",
              "      <td>[Anticipating the inevitable: When leader and ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>W2904069587</td>\n",
              "      <td>Chiffres et lettres</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>W2345552705</td>\n",
              "      <td>[Chemical control of rust (Uromyces phaseoli v...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02bf2942-7d7c-4f41-82c4-1700304a5e9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02bf2942-7d7c-4f41-82c4-1700304a5e9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02bf2942-7d7c-4f41-82c4-1700304a5e9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cad45f05-5cd4-44bf-9674-2c6c8f09ee96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cad45f05-5cd4-44bf-9674-2c6c8f09ee96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cad45f05-5cd4-44bf-9674-2c6c8f09ee96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wrangled_work_df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wrangled_work_df[\"referenced_works\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZnYinc6zQ8T",
        "outputId": "b59a4dc0-1b43-41fb-afd6-20c9b1f53a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wrangled_work_df[\"related_work_titles\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0YPaQY4zbyp",
        "outputId": "fb404c9f-7042-4f14-99f4-13a1fb31671c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wrangled_work_df[\"ngrams\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC5lDjnCzg6G",
        "outputId": "f79e6023-e556-4343-baf0-bb0239f761e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Store the values in Sqlite3 Database"
      ],
      "metadata": {
        "id": "9lHbroCu19u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sqlite3\n",
        "\n",
        "# Convert list columns to JSON strings\n",
        "wrangled_work_df['referenced_works'] = wrangled_work_df['referenced_works'].apply(json.dumps)\n",
        "wrangled_work_df['related_work_titles'] = wrangled_work_df['related_work_titles'].apply(json.dumps)\n",
        "wrangled_work_df['ngrams'] = wrangled_work_df['ngrams'].apply(json.dumps)\n",
        "\n",
        "wrangled_work_df['nearest_related_work'] = wrangled_work_df['nearest_related_work'].apply(json.dumps)\n",
        "wrangled_work_df['nearest_referenced_work'] = wrangled_work_df['nearest_referenced_work'].apply(json.dumps)\n",
        "wrangled_work_df['nearest_ngrams_work'] = wrangled_work_df['nearest_ngrams_work'].apply(json.dumps)\n",
        "\n",
        "\n",
        "\n",
        "# Connect to SQLite\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Convert DataFrame to SQLite\n",
        "wrangled_work_df.to_sql('works_table', works_db, index=False, if_exists='replace')\n",
        "\n",
        "# Save (commit) the changes\n",
        "works_db.commit()\n",
        "\n",
        "# Close the connection\n",
        "works_db.close()"
      ],
      "metadata": {
        "id": "AQwKklGj2C8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fetch again"
      ],
      "metadata": {
        "id": "O9E9UBfP-ASW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query\n",
        "query = \"SELECT * FROM works_table\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "\n",
        "# Iterate over the results\n",
        "for result in results:\n",
        "    (work_id,\n",
        "     title,\n",
        "     referenced_works_json,\n",
        "     related_work_titles_json,\n",
        "     ngrams_json,\n",
        "     nearest_referenced_work_json,\n",
        "     nearest_related_work_json,\n",
        "     nearest_ngrams_work_json)= result\n",
        "\n",
        "    # Parse JSON strings back to Python objects\n",
        "    referenced_works = json.loads(referenced_works_json)\n",
        "    related_work_titles = json.loads(related_work_titles_json)\n",
        "    ngrams = json.loads(ngrams_json)\n",
        "    nearest_referenced_work = json.loads(nearest_referenced_work_json)\n",
        "    nearest_related_work = json.loads(nearest_related_work_json)\n",
        "    nearest_ngrams_work = json.loads(nearest_ngrams_work_json)\n",
        "\n",
        "    # Now you have the data as lists of strings\n",
        "    print(\"Work ID:\", work_id)\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Referenced Works:\", referenced_works)\n",
        "    print(\"Related Work Titles:\", related_work_titles)\n",
        "    print(\"Ngrams:\", ngrams)\n",
        "    print(\"Nearest Referenced Work Titles:\", nearest_referenced_work)\n",
        "    print(\"Nearest Related Work Titles:\", nearest_related_work)\n",
        "    print(\"Nearest Ngrams:\", nearest_ngrams_work)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZpPhSpO-BeA",
        "outputId": "3bd107cd-a575-497c-d1b0-db5450f2e4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Work ID: W4205227400\n",
            "Title: SunTrust Banks, Inc.\n",
            "Referenced Works: []\n",
            "Related Work Titles: ['Regulation, Deregulation, Reregulation: The Future of the Banking, Insurance, and Securities Industries', 'Participation of Investment Banks and Non-Bank Financial Institutions in Syndicated Loans', 'Privacy Notices under the Gramm—Leach—Bliley Act']\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W2015602200\n",
            "Title: A constant rounds group key agreement protocol without using hash functions\n",
            "Referenced Works: ['Scalable Protocols for Authenticated Group Key Exchange', 'Authenticated key agreement without using one-way hash functions', 'Remarks on unknown key-share attack on authenticated multiple-key agreement protocol']\n",
            "Related Work Titles: ['Authentication for distributed systems', 'Research of AAA messages Based on 802.1x authentication', 'A Sidechain-Based Decentralized Authentication Scheme via Optimized Two-Way Peg Protocol for Smart Community']\n",
            "Ngrams: ['1', 'key', '\\uf8ef']\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W2952852381\n",
            "Title: Equity investigation of attitudinal shifts in introductory physics\n",
            "Referenced Works: ['Modeling theory applied: Modeling Instruction in introductory physics', 'Characterizing the gender gap in introductory physics', 'Gender gap on concept inventories in physics: What is consistent, what is inconsistent, and what factors influence the gap?']\n",
            "Related Work Titles: ['Anticipating the inevitable: When leader and member attribution styles clash', 'Informational cues and attributions based on role behavior', 'Susquehanna Chorale Spring Concert \"Roots and Wings\"']\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W2904069587\n",
            "Title: Chiffres et lettres\n",
            "Referenced Works: []\n",
            "Related Work Titles: []\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W2345552705\n",
            "Title: [Chemical control of rust (Uromyces phaseoli var. typica Arth) on voluble beans (Phaseolus vulgaris L.) mortino variety, under two cropping systems on the high plateau of Pasto, Department of Narino [Colombia]]. [Spanish]\n",
            "Referenced Works: []\n",
            "Related Work Titles: []\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W3000345438\n",
            "Title: Modeling text embedded information cascades\n",
            "Referenced Works: ['Feature-Enhanced Probabilistic Models for Diffusion Network Inference', 'Memes Online: Extracted, Subtracted, Injected, and Recollected', 'Automatically Constructing a Corpus of Sentential Paraphrases.']\n",
            "Related Work Titles: ['Development of a practical system for text content analysis and mining', 'ASKNet: automatically creating semantic knowledge networks from natural language text', 'An Architecture for Distributed Natural Language Summarization']\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W2008986850\n",
            "Title: Estimation of mortality coefficients and survivorship curves for minke whales (<i>Balaenoptera acutorostrata</i>) in Korean waters\n",
            "Referenced Works: ['Predicted decline of protected whales based on molecular genetic monitoring of Japanese and Korean markets', 'THE LIFE HISTORY OF FREE‐RANGING ATLANTIC SPOTTED DOLPHINS <i>(STENELLA FRONTALIS):</i> AGE CLASSES, COLOR PHASES, AND FEMALE REPRODUCTION', 'Demography of the endangered North Atlantic right whale']\n",
            "Related Work Titles: ['Dwarf Minke Whale (Balaenoptera acutorostrata)', 'The cardiac ventricles of a baleen whale (<i>Balaenoptera acutorostrata</i>: Minke whale) and a toothed whale (<i>Hyperoodon ampullatus</i>: Bottlenose whale)', 'Toxaphene in minke whales (Balaenoptera acutorostrata) from the North Atlantic']\n",
            "Ngrams: ['t', 'estimate', 'whale']\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W4253524524\n",
            "Title: Universal Screening of SARS-CoV-2 of Oncology Healthcare Workers — a Brazilian experience\n",
            "Referenced Works: []\n",
            "Related Work Titles: ['Nipah virus outbreak with person-to-person transmission in a district of Bangladesh, 2007', 'Symptomatic and asymptomatic transmission of SARS-CoV-2 in K-12 schools, British Columbia, April to June 2021', 'Epidemiological Modeling Analysis Reveals the Transmission Potential of COVID-19 Asymptomatic Patients:A Prospective Study of Epidemiological Transmission in America']\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W4310782751\n",
            "Title: THE RELATIONSHIP OF CLINICAL AND MORPHOLOGICAL DATA IN COMMINUTED FRACTURES OF THE LOWER JAW\n",
            "Referenced Works: ['Titanium Mesh Shaping and Fixation for the Treatment of Comminuted Mandibular Fractures', 'Evidence-Based Medicine: Mandible Fractures', 'Incidence and risk factors of the temporomandibular joint disorders in the patients without condylar fractures']\n",
            "Related Work Titles: ['[The healing of osteotomies of the lower jaw and the adaptation of the masticatory muscles after miniplate osteosynthesis in rabbits. I. Radiologic and histological evaluation of the lower jaw].', 'EXOSKELETON FOR LOWER JAW FRACTURES TREATMENT', 'THE WAY OF IMPROVING THE REPARATIVE OSTEOGENESIS IN THE CASE OF THE LOWER JAW FRACTURE']\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n",
            "Work ID: W1592839950\n",
            "Title: The health of the school child? An historical comparison of inspection schemes in Britain and Norway.\n",
            "Referenced Works: []\n",
            "Related Work Titles: ['The Causes Analysis and Measures of Electrical Porcelain Loss Caused by Firing', 'Diagnosis of Terra-Cotta Glaze Spalling', 'Modern outdoor insulation - concerns and challenges']\n",
            "Ngrams: []\n",
            "Nearest Referenced Work Titles: nan\n",
            "Nearest Related Work Titles: nan\n",
            "Nearest Ngrams: nan\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the Voyage API to cluster and find Top-k values"
      ],
      "metadata": {
        "id": "WNFFUiRA-lHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install voyageai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbEupUED-qbv",
        "outputId": "83b8c659-f5ac-424d-cef2-dea1251e7713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting voyageai\n",
            "  Downloading voyageai-0.1.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.5 in /usr/local/lib/python3.10/dist-packages (from voyageai) (3.9.3)\n",
            "Collecting aiolimiter<2.0.0,>=1.1.0 (from voyageai)\n",
            "  Downloading aiolimiter-1.1.0-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.10/dist-packages (from voyageai) (1.25.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.20 in /usr/local/lib/python3.10/dist-packages (from voyageai) (2.31.0)\n",
            "Requirement already satisfied: tenacity>=8.0.1 in /usr/local/lib/python3.10/dist-packages (from voyageai) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.5->voyageai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.5->voyageai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.5->voyageai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.5->voyageai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.5->voyageai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.5->voyageai) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20->voyageai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20->voyageai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20->voyageai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20->voyageai) (2024.2.2)\n",
            "Installing collected packages: aiolimiter, voyageai\n",
            "Successfully installed aiolimiter-1.1.0 voyageai-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set the environment"
      ],
      "metadata": {
        "id": "Ks4UBg-X-xkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import voyageai\n",
        "os.environ['VOYAGE_API_KEY'] = \"pa-k2_wb1Mj37_Ppl1FFBmCvu-ybdIKZzels0GeMF7PnUI\"\n",
        "vo = voyageai.Client(api_key=os.environ.get(\"VOYAGE_API_KEY\"),)"
      ],
      "metadata": {
        "id": "byTWaHuR-zk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set the Document values [This is an example usage]"
      ],
      "metadata": {
        "id": "rGYH6E9s_Qlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "# Fetch the sample documents\n",
        "related_documents = []\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query\n",
        "query = \"SELECT * FROM works_table LIMIT 1\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "\n",
        "# Iterate over the results\n",
        "for result in results:\n",
        "    work_id, title, referenced_works_json, related_work_titles_json, ngrams_json = result\n",
        "\n",
        "    # Parse JSON strings back to Python objects\n",
        "    referenced_works = json.loads(referenced_works_json)\n",
        "    related_work_titles = json.loads(related_work_titles_json)\n",
        "    ngrams = json.loads(ngrams_json)\n",
        "\n",
        "    # store the related documents\n",
        "    related_documents = related_work_titles\n",
        "\n",
        "    # Now you have the data as lists of strings\n",
        "    print(\"Work ID:\", work_id)\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Referenced Works:\", referenced_works)\n",
        "    print(\"Related Work Titles:\", related_work_titles)\n",
        "    print(\"Ngrams:\", ngrams)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZV0ZyGo_THW",
        "outputId": "67af8159-9bcf-4f6c-8a16-fe85c9debce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Work ID: W4205227400\n",
            "Title: SunTrust Banks, Inc.\n",
            "Referenced Works: []\n",
            "Related Work Titles: ['Regulation, Deregulation, Reregulation: The Future of the Banking, Insurance, and Securities Industries', 'Participation of Investment Banks and Non-Bank Financial Institutions in Syndicated Loans', 'Privacy Notices under the Gramm—Leach—Bliley Act']\n",
            "Ngrams: []\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This model version performs better than other model versions specifically fine-tuned for clustering problems"
      ],
      "metadata": {
        "id": "eQqfZF0C-6-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed the documents\n",
        "related_documents_embeddings = vo.embed(related_documents, model=\"voyage-lite-02-instruct\", input_type=\"document\").embeddings"
      ],
      "metadata": {
        "id": "G0EPjaVa_DrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To find out the document that is most similar to the query among the existing data, we can first embed/vectorize the query:"
      ],
      "metadata": {
        "id": "NDy7Wag1BFGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the embedding of the query in our case title\n",
        "title_embedding = vo.embed([title], model=\"voyage-lite-02-instruct\", input_type=\"query\").embeddings[0]"
      ],
      "metadata": {
        "id": "8a7eVC-cBG2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nearest neighbor Search:** We can find a few closest embeddings in the documents embeddings based on the cosine similarity, and retrieve the corresponding document using the nearest_neighbors function."
      ],
      "metadata": {
        "id": "V-D2JVKiBl6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def k_nearest_neighbors(query_embedding, documents_embeddings, k=5):\n",
        "  query_embedding = np.array(query_embedding) # convert to numpy array\n",
        "  documents_embeddings = np.array(documents_embeddings) # convert to numpy array\n",
        "\n",
        "  # Reshape the query vector embedding to a matrix of shape (1, n) to make it compatible with cosine_similarity\n",
        "  query_embedding = query_embedding.reshape(1, -1)\n",
        "\n",
        "  # Calculate the similarity for each item in data\n",
        "  cosine_sim = cosine_similarity(query_embedding, documents_embeddings)\n",
        "\n",
        "  # Sort the data by similarity in descending order and take the top k items\n",
        "  sorted_indices = np.argsort(cosine_sim[0])[::-1]\n",
        "\n",
        "  # Take the top k related embeddings\n",
        "  top_k_related_indices = sorted_indices[:k]\n",
        "  top_k_related_embeddings = documents_embeddings[sorted_indices[:k]]\n",
        "  top_k_related_embeddings = [list(row[:]) for row in top_k_related_embeddings] # convert to list\n",
        "\n",
        "  return top_k_related_embeddings, top_k_related_indices"
      ],
      "metadata": {
        "id": "sg4cVbk3Bmzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **$k$-nearest neighbors Search ($k$-NN):** It is often useful to retrieve not only the closest document but also the $k$ most closest documents. The k_nearest_neighbors algorithm enables us to achieve this. It is important to note that `nearest_neighbors` is special case of `k_nearest_neighbors` when $k=1$."
      ],
      "metadata": {
        "id": "_9FDsf1aB5oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the k-nearest neighbor algorithm to identify the top-k documents with the highest similarity\n",
        "retrieved_embds, retrieved_embd_indices = k_nearest_neighbors(title_embedding, related_documents_embeddings, k=1)\n",
        "retrieved_docs = [related_documents[index] for index in retrieved_embd_indices]\n",
        "\n",
        "print(retrieved_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pznLDFELB8da",
        "outputId": "5a132576-8c26-42d3-c53a-d347d471abc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Participation of Investment Banks and Non-Bank Financial Institutions in Syndicated Loans']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Expand** this code to allow multiple values"
      ],
      "metadata": {
        "id": "AgePDlGFFxt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import requests\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query\n",
        "query = \"SELECT * FROM works_table\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "\n",
        "# Iterate over the results\n",
        "for result in results:\n",
        "    (work_id,\n",
        "     title,\n",
        "     referenced_works_json,\n",
        "     related_work_titles_json,\n",
        "     ngrams_json,\n",
        "     nearest_referenced_work_json,\n",
        "     nearest_related_work_json,\n",
        "     nearest_ngrams_work_json) = result\n",
        "\n",
        "    # Parse JSON strings back to Python objects\n",
        "    referenced_works = json.loads(referenced_works_json)\n",
        "    related_work_titles = json.loads(related_work_titles_json)\n",
        "    ngrams = json.loads(ngrams_json)\n",
        "\n",
        "    # Lists to store retrieved documents\n",
        "    nearest_referenced_work = \"\"\n",
        "    nearest_related_work = \"\"\n",
        "    nearest_ngrams_work = \"\"\n",
        "\n",
        "\n",
        "    # Embed the title\n",
        "    title_embedding = vo.embed([title], model=\"voyage-lite-02-instruct\", input_type=\"query\").embeddings[0]\n",
        "\n",
        "    # Store the referenced_works for processing\n",
        "    if referenced_works:\n",
        "      # Store the referenced for processing\n",
        "      referenced_documents = referenced_works\n",
        "\n",
        "      # Embed the referenced\n",
        "      referenced_documents_embeddings = vo.embed(referenced_documents, model=\"voyage-lite-02-instruct\", input_type=\"document\").embeddings\n",
        "\n",
        "      # Find the nearest neighbor and store in the nearest referenced work\n",
        "      retrieved_embds, retrieved_embd_indices = k_nearest_neighbors(title_embedding, referenced_documents_embeddings, k=1)\n",
        "      nearest_referenced_work = referenced_documents[retrieved_embd_indices[0]]\n",
        "\n",
        "    if related_work_titles:\n",
        "      # Store the related_works for processing\n",
        "      related_documents = related_work_titles\n",
        "\n",
        "      # Embed the related_works\n",
        "      related_documents_embeddings = vo.embed(related_documents, model=\"voyage-lite-02-instruct\", input_type=\"document\").embeddings\n",
        "\n",
        "      # Find the nearest neighbor and store in the nearest related work\n",
        "      retrieved_embds, retrieved_embd_indices = k_nearest_neighbors(title_embedding, related_documents_embeddings, k=1)\n",
        "      nearest_related_work = related_documents[retrieved_embd_indices[0]]\n",
        "\n",
        "    # Embed the ngrams if the list has values\n",
        "    if ngrams:\n",
        "      # Store the ngrams_works for processing\n",
        "      ngrams_documents = ngrams\n",
        "\n",
        "      # Embed the ngrams_works\n",
        "      ngrams_documents_embeddings = vo.embed(ngrams_documents, model=\"voyage-lite-02-instruct\", input_type=\"document\").embeddings\n",
        "\n",
        "      # Find the nearest neighbor and store in the nearest ngram work\n",
        "      retrieved_embds, retrieved_embd_indices = k_nearest_neighbors(title_embedding, ngrams_documents_embeddings, k=1)\n",
        "      nearest_ngrams_work = ngrams_documents[retrieved_embd_indices[0]]\n",
        "\n",
        "    # Update the SQLite database with the retrieved documents\n",
        "    update_query = f\"UPDATE works_table SET nearest_related_work = ?, nearest_referenced_work = ?, nearest_ngrams_work = ? WHERE work_id = ?\"\n",
        "    work_cursor.execute(update_query, (nearest_related_work, nearest_referenced_work, nearest_ngrams_work, work_id))\n",
        "    works_db.commit()\n",
        "\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "id": "MAgQypIKF14-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query (using this as an example because it has all the values)\n",
        "query = \"SELECT * FROM works_table WHERE work_id like 'W2015602200'\"\n",
        "work_cursor.execute(query)\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nkTx6C7MtjD",
        "outputId": "a7fd3e8c-2f98-403f-ac1c-257942b21156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('W2015602200',\n",
              "  'A constant rounds group key agreement protocol without using hash functions',\n",
              "  '[\"Scalable Protocols for Authenticated Group Key Exchange\", \"Authenticated key agreement without using one-way hash functions\", \"Remarks on unknown key-share attack on authenticated multiple-key agreement protocol\"]',\n",
              "  '[\"Authentication for distributed systems\", \"Research of AAA messages Based on 802.1x authentication\", \"A Sidechain-Based Decentralized Authentication Scheme via Optimized Two-Way Peg Protocol for Smart Community\"]',\n",
              "  '[\"1\", \"key\", \"\\\\uf8ef\"]',\n",
              "  'A Sidechain-Based Decentralized Authentication Scheme via Optimized Two-Way Peg Protocol for Smart Community',\n",
              "  'Scalable Protocols for Authenticated Group Key Exchange',\n",
              "  'key')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Make a training pair** using the column values from the table"
      ],
      "metadata": {
        "id": "hjxjCj2W3uNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Title Refereced Work JSON"
      ],
      "metadata": {
        "id": "L3lUdwO49ttL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query only the rows having value and limiting the number to 10k\n",
        "query = \"SELECT * FROM works_table WHERE length(nearest_referenced_work) > 0 LIMIT 5\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "\n",
        "# Define the path for the JSONL file\n",
        "jsonl_file_path = \"title_referenced_work.jsonl\"\n",
        "\n",
        "# Open the JSONL file in write mode\n",
        "with open(jsonl_file_path, \"w\") as jsonl_file:\n",
        "    # Iterate over the results\n",
        "    for result in results:\n",
        "        work_id, title, referenced_works_json, related_work_titles_json, ngrams_json, \\\n",
        "        nearest_related_work, nearest_referenced_work, nearest_ngrams_work = result\n",
        "\n",
        "        # Extract values for JSONL format\n",
        "        anchor_text = title\n",
        "        positive_text = nearest_referenced_work\n",
        "\n",
        "        # Create a dictionary for positive pairs\n",
        "        positive_pairs = {\"texts\": [anchor_text, positive_text]}\n",
        "\n",
        "        # Write the positive pairs dictionary as a JSON string to the JSONL file\n",
        "        jsonl_file.write(json.dumps(positive_pairs) + \"\\n\")\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "id": "ZAHomRD632Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Title Related Work JSON"
      ],
      "metadata": {
        "id": "xfQHITrz9_Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query only the rows having value and limiting the number to 10k\n",
        "query = \"SELECT * FROM works_table WHERE length(nearest_related_work) > 0 LIMIT 5\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "\n",
        "# Define the path for the JSONL file\n",
        "jsonl_file_path = \"title_related_work.jsonl\"\n",
        "\n",
        "# Open the JSONL file in write mode\n",
        "with open(jsonl_file_path, \"w\") as jsonl_file:\n",
        "    # Iterate over the results\n",
        "    for result in results:\n",
        "        work_id, title, referenced_works_json, related_work_titles_json, ngrams_json, \\\n",
        "        nearest_related_work, nearest_referenced_work, nearest_ngrams_work = result\n",
        "\n",
        "        # Extract values for JSONL format\n",
        "        anchor_text = title\n",
        "        positive_text = nearest_related_work\n",
        "\n",
        "        # Create a dictionary for positive pairs\n",
        "        positive_pairs = {\"texts\": [anchor_text, positive_text]}\n",
        "\n",
        "        # Write the positive pairs dictionary as a JSON string to the JSONL file\n",
        "        jsonl_file.write(json.dumps(positive_pairs) + \"\\n\")\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "id": "XchmpCdd-AW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Title Ngrams Work JSON"
      ],
      "metadata": {
        "id": "aM_fB7c3-Azo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database\n",
        "works_db = sqlite3.connect(\"works.db\")\n",
        "\n",
        "# Create a cursor\n",
        "work_cursor = works_db.cursor()\n",
        "\n",
        "# Execute a SELECT query only the rows having value and limiting the number to 10k\n",
        "query = \"SELECT * FROM works_table WHERE length(nearest_ngrams_work) > 0 LIMIT 5\"\n",
        "work_cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "results = work_cursor.fetchall()\n",
        "\n",
        "# Define the path for the JSONL file\n",
        "jsonl_file_path = \"title_ngrams_work.jsonl\"\n",
        "\n",
        "# Open the JSONL file in write mode\n",
        "with open(jsonl_file_path, \"w\") as jsonl_file:\n",
        "    # Iterate over the results\n",
        "    for result in results:\n",
        "        work_id, title, referenced_works_json, related_work_titles_json, ngrams_json, \\\n",
        "        nearest_related_work, nearest_referenced_work, nearest_ngrams_work = result\n",
        "\n",
        "        # Extract values for JSONL format\n",
        "        anchor_text = title\n",
        "        positive_text = nearest_ngrams_work\n",
        "\n",
        "        # Create a dictionary for positive pairs\n",
        "        positive_pairs = {\"texts\": [anchor_text, positive_text]}\n",
        "\n",
        "        # Write the positive pairs dictionary as a JSON string to the JSONL file\n",
        "        jsonl_file.write(json.dumps(positive_pairs) + \"\\n\")\n",
        "\n",
        "# Close the cursor and connection\n",
        "work_cursor.close()\n",
        "works_db.close()"
      ],
      "metadata": {
        "id": "caiKVpJE-B_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Triplets from Topics"
      ],
      "metadata": {
        "id": "3xaffiZJSWGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Keywords Topic"
      ],
      "metadata": {
        "id": "TnhbEmSgWt64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "def fetch_and_store_data(url, output_file, target_count=1,delay=1):\n",
        "    # Initialize counters\n",
        "    total_keywords_count = 0\n",
        "    total_entries_count = 0\n",
        "\n",
        "    # Loop until the target count is reached\n",
        "    while total_entries_count < target_count:\n",
        "        # Fetch data from the URL\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract relevant information and store in the desired format\n",
        "        results = data.get(\"results\", [])\n",
        "        formatted_data = []\n",
        "\n",
        "        for result in results:\n",
        "            display_name = result.get(\"display_name\", \"\")\n",
        "            keywords = result.get(\"keywords\", [])\n",
        "\n",
        "            if keywords:\n",
        "                # Extracting the top-scored keyword text\n",
        "                top_keyword = keywords[0]\n",
        "\n",
        "                # Creating the structure {\"texts\": [\"display_name\", \"key\"]}\n",
        "                formatted_entry = {\"texts\": [display_name, top_keyword]}\n",
        "                formatted_data.append(formatted_entry)\n",
        "                total_keywords_count += 1\n",
        "\n",
        "        # Write to a .jsonl file\n",
        "        with open(output_file, \"a\") as jsonl_file:\n",
        "            for entry in formatted_data:\n",
        "                jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
        "                total_entries_count += 1\n",
        "\n",
        "        # Delay for 1 second before the next API call due to rate limit\n",
        "        time.sleep(delay)\n",
        "\n",
        "    print(f\"Total entries with keywords: {total_keywords_count}\")\n",
        "    print(f\"Total entries written to {output_file}: {total_entries_count}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the URL and output file\n",
        "    api_url = \"https://api.openalex.org/topics?mailto=brookshum24@gmail.com&sample=1&seed=3&select=display_name,keywords\"\n",
        "    output_jsonl_file = \"topic_name_key.jsonl\"\n",
        "\n",
        "    # Fetch and store the data\n",
        "    fetch_and_store_data(api_url, output_jsonl_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z68dnB1Wvgi",
        "outputId": "b17fa428-bb44-48d0-8327-d10679d7f4f2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total entries with keywords: 1\n",
            "Total entries written to topic_name_key.jsonl: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Triplet display name , domain , field  [Hard-negative]\n",
        "#### This applies to the display name , domain , sub-field  [soft-negative]\n",
        "#### This also applies to the display name , field, sub-field [Hard-negative]"
      ],
      "metadata": {
        "id": "IACRyNFVXqVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "def fetch_and_store_topics(url, output_file, target_count=1, delay=1):\n",
        "    # Initialize counters\n",
        "    total_entries_count = 0\n",
        "\n",
        "    # Loop until the target count is reached\n",
        "    while total_entries_count < target_count:\n",
        "        # Fetch data from the URL\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract relevant information and store in the desired format\n",
        "        results = data.get(\"results\", [])\n",
        "        formatted_data = []\n",
        "\n",
        "        for result in results:\n",
        "            display_name = result.get(\"display_name\", \"\")\n",
        "            domain = result.get(\"domain\", {}).get(\"display_name\", \"\")\n",
        "            field = result.get(\"field\", {}).get(\"display_name\", \"\")\n",
        "\n",
        "            # Create the triplet {\"texts\": [\"display_name\", \"domain\", \"field\"]}\n",
        "            formatted_entry = {\"texts\": [display_name, domain, field]}\n",
        "            formatted_data.append(formatted_entry)\n",
        "            total_entries_count += 1\n",
        "\n",
        "        # Write to a .jsonl file\n",
        "        with open(output_file, \"a\") as jsonl_file:\n",
        "            for entry in formatted_data:\n",
        "                jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "        # Delay for 1 second before the next API call due to rate limit\n",
        "        time.sleep(delay)\n",
        "\n",
        "    print(f\"Total entries written to {output_file}: {total_entries_count}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the URL and output file\n",
        "    topics_url = \"https://api.openalex.org/topics?mailto=brookshum24@gmail.com&sample=2&seed=3&select=display_name,domain,field\"\n",
        "    output_jsonl_file = \"topics_triplets.jsonl\"\n",
        "\n",
        "    # Fetch and store the topics data\n",
        "    fetch_and_store_topics(topics_url, output_jsonl_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoCHEHtiYiX8",
        "outputId": "8ef4e6fc-c10f-411f-a731-3739212cb075"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total entries written to topics_triplets.jsonl: 2\n"
          ]
        }
      ]
    }
  ]
}